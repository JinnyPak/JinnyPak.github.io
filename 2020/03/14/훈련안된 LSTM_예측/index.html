<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>훈련안된 LSTM_예측 | Jinny Pak&#39;s Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1234from tensorflow.keras.preprocessing.text import Tokenizerfrom tensorflow.keras.preprocessing.sequence import pad_sequencesimport numpy as npimport pandas as pd  전처리1text_dataset&#x3D;pd.read_csv(&#39;text_">
<meta property="og:type" content="article">
<meta property="og:title" content="훈련안된 LSTM_예측">
<meta property="og:url" content="http://jinnypak.github.io/2020/03/14/%ED%9B%88%EB%A0%A8%EC%95%88%EB%90%9C%20LSTM_%EC%98%88%EC%B8%A1/index.html">
<meta property="og:site_name" content="Jinny Pak&#39;s Hexo">
<meta property="og:description" content="1234from tensorflow.keras.preprocessing.text import Tokenizerfrom tensorflow.keras.preprocessing.sequence import pad_sequencesimport numpy as npimport pandas as pd  전처리1text_dataset&#x3D;pd.read_csv(&#39;text_">
<meta property="og:locale" content="ko_KR">
<meta property="article:published_time" content="2020-03-14T04:54:54.162Z">
<meta property="article:modified_time" content="2020-03-14T03:44:14.038Z">
<meta property="article:author" content="Jinny Pak">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Jinny Pak&#39;s Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Jinny Pak&#39;s Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="검색"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://JinnyPak.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-훈련안된 LSTM_예측" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/14/%ED%9B%88%EB%A0%A8%EC%95%88%EB%90%9C%20LSTM_%EC%98%88%EC%B8%A1/" class="article-date">
  <time datetime="2020-03-14T04:54:54.162Z" itemprop="datePublished">2020-03-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      훈련안된 LSTM_예측
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>

<h2 id="전처리"><a href="#전처리" class="headerlink" title="전처리"></a>전처리</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text_dataset=pd.read_csv(<span class="string">'text_dataset_2015_2019.csv'</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">meta_2015_2019=pd.read_csv(<span class="string">'meta_dataset_2015_2019.csv'</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ks_text_state=pd.concat([text_dataset[[<span class="string">'content'</span>,<span class="string">'risk_challenge'</span>]],meta_2015_2019[<span class="string">'state'</span>]],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 결측치 확인</span></span><br><span class="line">ks_text_state.isna().sum()</span><br></pre></td></tr></table></figure>




<pre><code>content            27
risk_challenge    189
state               0
dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#null인 행 걸러내기</span></span><br><span class="line">null_index=ks_text_state[ks_text_state.content.isna()].index.tolist()</span><br><span class="line">ks_text_state=ks_text_state.drop(null_index)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#공백이 있는 content 걸러내기</span></span><br><span class="line">cont_null_index=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> ks_text_state.index:</span><br><span class="line">    <span class="keyword">if</span> ks_text_state.content.loc[i]==<span class="string">"[]"</span>:</span><br><span class="line">        cont_null_index.append(i)</span><br><span class="line"></span><br><span class="line">ks_text_state.loc[cont_null_index]</span><br><span class="line">ks_text_state=ks_text_state.drop(cont_null_index)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ks_text_state</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>content</th>
      <th>risk_challenge</th>
      <th>state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>['Meet Jane Bowles: incredible author, inspiri...</td>
      <td>The main obstacles this book faces are the siz...</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>1</th>
      <td>["I've always been passionate about efficiency...</td>
      <td>The biggest challenge in completing this proje...</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>2</th>
      <td>['Billet Dice', 'Billet Dice are made from bil...</td>
      <td>The international shipping is a worry but I wa...</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>3</th>
      <td>['With this film we want to entertain you in a...</td>
      <td>We will be using the money to prevent any prob...</td>
      <td>failed</td>
    </tr>
    <tr>
      <th>4</th>
      <td>['The Splash Drone is a fully waterproof quad ...</td>
      <td>We have spent countless hours and many months ...</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>153570</th>
      <td>['Vivian is a New York–based design label star...</td>
      <td>There are always risks and challenges when it ...</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>153571</th>
      <td>['Hello there! My name is Chloe and I’m the ar...</td>
      <td>• The finished product’s colours may appear di...</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>153572</th>
      <td>["For the relaunch of the Beastly Boutique, I ...</td>
      <td>Once funded, if there are any delays in produc...</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>153573</th>
      <td>['Your application to become a Produce Social ...</td>
      <td>This project depends on fundraising. We need t...</td>
      <td>failed</td>
    </tr>
    <tr>
      <th>153574</th>
      <td>["I'm a Contemporary Christian artist. I want ...</td>
      <td>The only risk I would anticipate is an untimel...</td>
      <td>failed</td>
    </tr>
  </tbody>
</table>
<p>151061 rows × 3 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">risk_isna=ks_text_state[ks_text_state.risk_challenge.isna()].index.tolist()</span><br><span class="line"></span><br><span class="line">ks_text_state.loc[risk_isna]</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>content</th>
      <th>risk_challenge</th>
      <th>state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>420</th>
      <td>["WHAT IS PALS MAGAZINE?It will be published e...</td>
      <td>NaN</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>596</th>
      <td>["A play directed by Josh Whatsize for IYAF in...</td>
      <td>NaN</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>1616</th>
      <td>["Ladies and Gent's,", "As we know - time is m...</td>
      <td>NaN</td>
      <td>failed</td>
    </tr>
    <tr>
      <th>3600</th>
      <td>['Our show highlights some of the best talent ...</td>
      <td>NaN</td>
      <td>failed</td>
    </tr>
    <tr>
      <th>3918</th>
      <td>['N/A']</td>
      <td>NaN</td>
      <td>failed</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>133151</th>
      <td>['Only for those who aspire to greatness and d...</td>
      <td>NaN</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>142491</th>
      <td>['Five friends have a seance in a cemetery. Te...</td>
      <td>NaN</td>
      <td>failed</td>
    </tr>
    <tr>
      <th>144507</th>
      <td>['Hi everybody! As a lot of you have probably ...</td>
      <td>NaN</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>146244</th>
      <td>['Introducing Lavender Coco Kitchen: Book One,...</td>
      <td>NaN</td>
      <td>successful</td>
    </tr>
    <tr>
      <th>153062</th>
      <td>['Introducing Lavender Coco Kitchen: Book One,...</td>
      <td>NaN</td>
      <td>successful</td>
    </tr>
  </tbody>
</table>
<p>158 rows × 3 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ks_text_state.risk_challenge=ks_text_state.risk_challenge.fillna(<span class="string">" "</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 나중에 이미지,메타데이터와 합칠 때 인덱스를 맞추기위해 인덱스 리스트를 저장함 </span></span><br><span class="line">total_null_index=null_index+cont_null_index</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'total_null_index2.pkl'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(total_null_index,f)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ks_text_state[<span class="string">'all_text'</span>]=ks_text_state[<span class="string">'content'</span>]+ks_text_state[<span class="string">'risk_challenge'</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y=ks_text_state[<span class="string">'state'</span>]</span><br><span class="line">X=ks_text_state[<span class="string">'all_text'</span>]</span><br><span class="line">X.shape,y.shape</span><br></pre></td></tr></table></figure>

<pre><code>((151061,), (151061,))</code></pre><h2 id="텍스트-전처리"><a href="#텍스트-전처리" class="headerlink" title="텍스트 전처리"></a>텍스트 전처리</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#y label encoding</span></span><br><span class="line"><span class="comment">#라벨링</span></span><br><span class="line"><span class="comment">#Series를 받아서 라벨인코딩 처리하는 함수</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encoding</span><span class="params">(x)</span>:</span></span><br><span class="line">    col_dict=&#123;&#125;</span><br><span class="line">    le=LabelEncoder()</span><br><span class="line"><span class="comment">#fit()어떻게 변환할지 fitting</span></span><br><span class="line">    le.fit(x)</span><br><span class="line"><span class="comment">#변환</span></span><br><span class="line">    label_x=le.transform(x)</span><br><span class="line">    col_dict[x.name]=le.classes_</span><br><span class="line">    <span class="keyword">return</span> label_x</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_enc=encoding(y)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line"><span class="comment"># 전처리 함수</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text_preprocessing</span><span class="params">(document)</span>:</span></span><br><span class="line">    <span class="comment"># 소문자 변환</span></span><br><span class="line">    type(document)</span><br><span class="line">    document = document.lower()</span><br><span class="line">    document = document.replace(<span class="string">'\\xa0'</span>,<span class="string">' '</span>)</span><br><span class="line">    document = document.replace(<span class="string">'•\\t'</span>,<span class="string">' '</span>) </span><br><span class="line">    <span class="comment"># 특수문자 제거</span></span><br><span class="line">    pattern = <span class="string">'[&#123;&#125;]'</span>.format(string.punctuation)</span><br><span class="line">    document = re.sub(pattern, <span class="string">' '</span>, document)</span><br><span class="line">    <span class="comment"># stopword 제거, stemming</span></span><br><span class="line">    sw = stopwords.words(<span class="string">'english'</span>)+[<span class="string">'may'</span>]</span><br><span class="line">    word_token=nltk.word_tokenize(document)</span><br><span class="line">    stemmer = PorterStemmer()</span><br><span class="line"></span><br><span class="line">    result_token=[ stemmer.stem(word) <span class="keyword">for</span> word <span class="keyword">in</span> word_token <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> sw]</span><br><span class="line">    <span class="comment">#문자열로 변환 후 반환</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">' '</span>.join(result_token)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_list=list(X.values)</span><br><span class="line">text = [text_preprocessing(x) <span class="keyword">for</span> x <span class="keyword">in</span> X_list]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#전처리한 텍스트데이터 pickle저장</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'preprocessed_all_text.pkl'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(text,f)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'y_encoding.pkl'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(y_enc,f)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#읽기</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'y_encoding.pkl'</span>,<span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    y_enc=pickle.load(f)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'preprocessed_all_text.pkl'</span>,<span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    preprocessed_all_text=pickle.load(f)</span><br></pre></td></tr></table></figure>
<h2 id="Tokenize"><a href="#Tokenize" class="headerlink" title="Tokenize"></a>Tokenize</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">max_features=<span class="number">10000</span></span><br><span class="line">maxlen=<span class="number">500</span></span><br><span class="line">batch_size=<span class="number">32</span></span><br><span class="line">embedding_dim=<span class="number">300</span></span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(num_words=max_features)</span><br><span class="line">tokenizer.fit_on_texts(preprocessed_all_text)</span><br><span class="line">vocab_size = len(tokenizer.word_index) + <span class="number">1</span></span><br><span class="line">print(<span class="string">'단어 집합의 크기 : %d'</span> % vocab_size)</span><br></pre></td></tr></table></figure>

<pre><code>단어 집합의 크기 : 600997</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sequences=tokenizer.texts_to_sequences(preprocessed_all_text)</span><br><span class="line">word_index=tokenizer.word_index</span><br><span class="line">data=pad_sequences(sequences,maxlen=maxlen)</span><br><span class="line">data.shape</span><br></pre></td></tr></table></figure>
<pre><code>(151061, 500)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">labels=np.array(y_enc)</span><br><span class="line">labels.shape</span><br></pre></td></tr></table></figure>

<pre><code>(151061,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(data, labels,stratify=labels)</span><br><span class="line">X_train.shape,X_test.shape,y_train.shape,y_test.shape</span><br></pre></td></tr></table></figure>


<pre><code>((113295, 500), (37766, 500), (113295,), (37766,))</code></pre><h2 id="Modeling"><a href="#Modeling" class="headerlink" title="Modeling"></a>Modeling</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Embedding, Flatten, Dense,LSTM,Dropout</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_features, embedding_dim, input_length=maxlen))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 500, 300)          3000000   
_________________________________________________________________
lstm (LSTM)                  (None, 32)                42624     
_________________________________________________________________
dense (Dense)                (None, 32)                1056      
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 3,045,825
Trainable params: 3,045,825
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>,loss=<span class="string">'binary_crossentropy'</span>,metrics=[<span class="string">'accuracy'</span>,<span class="string">'AUC'</span>,<span class="string">'Recall'</span>,<span class="string">'Precision'</span>])</span><br></pre></td></tr></table></figure>

<pre><code>Train on 90636 samples, validate on 22659 samples
Epoch 1/10
90636/90636 [==============================] - 789s 9ms/sample - loss: 0.5440 - accuracy: 0.7493 - AUC: 0.7936 - Recall: 0.8531 - Precision: 0.7631 - val_loss: 0.5092 - val_accuracy: 0.7733 - val_AUC: 0.8428 - val_Recall: 0.8650 - val_Precision: 0.7844
Epoch 2/10
90636/90636 [==============================] - 793s 9ms/sample - loss: 0.4950 - accuracy: 0.7844 - AUC: 0.8355 - Recall: 0.8625 - Precision: 0.7993 - val_loss: 0.4988 - val_accuracy: 0.7568 - val_AUC: 0.8449 - val_Recall: 0.9520 - val_Precision: 0.7301
Epoch 3/10
90636/90636 [==============================] - 797s 9ms/sample - loss: 0.4702 - accuracy: 0.7952 - AUC: 0.8548 - Recall: 0.8798 - Precision: 0.8028 - val_loss: 0.4996 - val_accuracy: 0.7908 - val_AUC: 0.8585 - val_Recall: 0.8238 - val_Precision: 0.8308
Epoch 4/10
90636/90636 [==============================] - 788s 9ms/sample - loss: 0.4548 - accuracy: 0.8036 - AUC: 0.8662 - Recall: 0.8874 - Precision: 0.8087 - val_loss: 0.4596 - val_accuracy: 0.7841 - val_AUC: 0.8619 - val_Recall: 0.9223 - val_Precision: 0.7688
Epoch 5/10
90636/90636 [==============================] - 783s 9ms/sample - loss: 0.4409 - accuracy: 0.8099 - AUC: 0.8754 - Recall: 0.8961 - Precision: 0.8113 - val_loss: 0.4636 - val_accuracy: 0.7943 - val_AUC: 0.8659 - val_Recall: 0.8337 - val_Precision: 0.8290
Epoch 6/10
90636/90636 [==============================] - 792s 9ms/sample - loss: 0.4288 - accuracy: 0.8172 - AUC: 0.8835 - Recall: 0.9043 - Precision: 0.8155 - val_loss: 0.5237 - val_accuracy: 0.7783 - val_AUC: 0.8610 - val_Recall: 0.9426 - val_Precision: 0.7542
Epoch 7/10
90636/90636 [==============================] - 795s 9ms/sample - loss: 0.4170 - accuracy: 0.8237 - AUC: 0.8909 - Recall: 0.9172 - Precision: 0.8160 - val_loss: 0.5347 - val_accuracy: 0.7792 - val_AUC: 0.8439 - val_Recall: 0.8483 - val_Precision: 0.8005
Epoch 8/10
90636/90636 [==============================] - 797s 9ms/sample - loss: 0.4077 - accuracy: 0.8285 - AUC: 0.8973 - Recall: 0.9234 - Precision: 0.8182 - val_loss: 0.5175 - val_accuracy: 0.7879 - val_AUC: 0.8556 - val_Recall: 0.8359 - val_Precision: 0.8189
Epoch 9/10
90636/90636 [==============================] - 807s 9ms/sample - loss: 0.3933 - accuracy: 0.8360 - AUC: 0.9057 - Recall: 0.9300 - Precision: 0.8235 - val_loss: 0.5019 - val_accuracy: 0.7921 - val_AUC: 0.8588 - val_Recall: 0.8952 - val_Precision: 0.7906
Epoch 10/10
90636/90636 [==============================] - 803s 9ms/sample - loss: 0.3836 - accuracy: 0.8415 - AUC: 0.9119 - Recall: 0.9340 - Precision: 0.8278 - val_loss: 0.5833 - val_accuracy: 0.7910 - val_AUC: 0.8561 - val_Recall: 0.8794 - val_Precision: 0.7976</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(X_test, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>37766/37766 [==============================] - 77s 2ms/sample - loss: 0.5847 - accuracy: 0.7868 - AUC: 0.8530 - Recall: 0.8688 - Precision: 0.7986





[0.5847473297212321, 0.7867659, 0.85300577, 0.8688332, 0.7985525]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 모델 저장</span></span><br><span class="line">model.save(<span class="string">'lstm_all_text.h5'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="저장한-모델-로드하여-예측하기"><a href="#저장한-모델-로드하여-예측하기" class="headerlink" title="저장한 모델 로드하여 예측하기"></a>저장한 모델 로드하여 예측하기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> load_model</span><br><span class="line">new_model = load_model(<span class="string">'lstm_all_text.h5'</span>)</span><br><span class="line"></span><br><span class="line">new_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 500, 300)          3000000   
_________________________________________________________________
lstm (LSTM)                  (None, 32)                42624     
_________________________________________________________________
dense (Dense)                (None, 32)                1056      
_________________________________________________________________
dropout (Dropout)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 3,045,825
Trainable params: 3,045,825
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test1_pre = [text_preprocessing(x) <span class="keyword">for</span> x <span class="keyword">in</span> test1]</span><br><span class="line">test1_pre</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = Tokenizer(num_words=max_features)</span><br><span class="line">tokenizer.fit_on_texts(test1_pre)</span><br><span class="line">vocab_size = len(tokenizer.word_index) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">sequences=tokenizer.texts_to_sequences(test1_pre)</span><br><span class="line">data=pad_sequences(sequences,maxlen=maxlen)</span><br><span class="line">data.shape</span><br></pre></td></tr></table></figure>
<pre><code>(1, 500)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pred_cls = new_model.predict_classes(data)</span><br><span class="line">pred_cls</span><br></pre></td></tr></table></figure>
<pre><code>array([[1]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pred_proba=new_model.predict_proba(data)</span><br><span class="line">pred_proba</span><br></pre></td></tr></table></figure>
<pre><code>array([[0.6899058]], dtype=float32)</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://jinnypak.github.io/2020/03/14/%ED%9B%88%EB%A0%A8%EC%95%88%EB%90%9C%20LSTM_%EC%98%88%EC%B8%A1/" data-id="ck86z3gsn0005t0uzd1ss8g0d" class="article-share-link">공유</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/25/crawling/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">최신</strong>
      <div class="article-nav-title">
        
          crawling
        
      </div>
    </a>
  
  
    <a href="/2020/02/21/nlp/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">이전</strong>
      <div class="article-nav-title">python_02_LSTM</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">아카이브</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">3월 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">2월 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">최근 포스트</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/03/25/crawling/">crawling</a>
          </li>
        
          <li>
            <a href="/2020/03/14/%ED%9B%88%EB%A0%A8%EC%95%88%EB%90%9C%20LSTM_%EC%98%88%EC%B8%A1/">훈련안된 LSTM_예측</a>
          </li>
        
          <li>
            <a href="/2020/02/21/nlp/">python_02_LSTM</a>
          </li>
        
          <li>
            <a href="/2020/02/16/python-01/">python_01_DTM/TF-IDF</a>
          </li>
        
          <li>
            <a href="/2020/02/16/test/">test 포스트</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Jinny Pak<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>